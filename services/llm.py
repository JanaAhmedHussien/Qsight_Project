import requests, json, config

class LLM:
    def generate_report(self, patient, diag):
        for fn in (
            ("ChatGPT", self._chatgpt),
            ("Gemini", self._gemini),
            ("Groq", self._groq),
            ("HuggingFace", self._hf),
        ):
            name, func = fn
            print(f"[LLM] Trying {name}...")
            result = func(patient, diag)
            if result:
                print(f"[LLM]  Response generated by {name}")
                return result

        print("[LLM]  No LLM responded successfully")
        return None


    def _base_prompt(self, patient, diag):
        return {
            "role": "user",
            "content": f"""
    You are a board-certified ophthalmologist specializing in diabetic retinopathy.
    Write a concise, clinical medical report.

    IMPORTANT RULES:
    - Return STRICT JSON only
    - No markdown
    - No filler phrases (e.g. "are recommended", "it is advised")
    - Use short clinical bullet-style sentences
    - Condense information; clarity over expressiveness
    - Lifestyle guidance should be specific (diet focus, eye protection, glycemic control)

    Patient:
    Name: {patient.name}
    Age: {patient.age}
    Sex: {patient.sex}
    Weight: {patient.weight}
    Height: {patient.height}
    BMI: {patient.bmi}
    Insulin: {patient.insulin}
    Smoker: {patient.smoker}
    Alcohol: {patient.alcohol}
    Vascular Disease: {patient.vascular}

    Diagnosis:
    Left Eye: {diag['retinopathy_left']}
    Right Eye: {diag['retinopathy_right']}
    Confidence: {diag['confidence']}
    Risk Score: {diag['risk']}

    JSON schema (concise, clinical tone):
    {{
    "condition_overview": "Brief definition and severity summary.",
    "patient_assessment": "Key risk factors and clinical interpretation.",
    "implications": "Potential visual and systemic consequences.",
    "treatment_plan": "Outline format. Clinical interventions and monitoring.",
    "life_impact": "Short bullet points. Daily vision and activity effects.",
    "financial_impact": "Expected cost categories (monitoring, therapy).",
    "recovery_projection": "Expected course with adherence.",
    "additional_assessments": "Required tests or referrals.",
    "compliance_notice": "Importance of follow-up and treatment adherence."
    }}

    Lifestyle guidance rules:
    - Diet: specify focus (glycemic control, low saturated fat, antioxidants)
    - Eye protection: UV protection explicitly stated
    - Avoid narrative language
    """
        }


    # ---------- ChatGPT ----------
    def _chatgpt(self, patient, diag):
        if not config.Config.OPENAI:
            return None
        try:
            r = requests.post(
                "https://api.openai.com/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {config.Config.OPENAI}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": "gpt-4o-mini",
                    "messages": [self._base_prompt(patient, diag)],
                    "temperature": 0.3
                },
                timeout=10
            ).json()
            return json.loads(r["choices"][0]["message"]["content"])
        except:
            return None

    # ---------- Gemini ----------
    def _gemini(self, patient, diag):
        if not config.Config.GEMINI:
            return None
        try:
            from google import genai
            c = genai.Client(api_key=config.Config.GEMINI)
            r = c.models.generate_content(
                model="gemini-2.5-flash",
                contents=self._base_prompt(patient, diag)["content"]
            )
            return json.loads(r.text)
        except:
            return None

    # ---------- Groq ----------
    def _groq(self, patient, diag):
        if not config.Config.GROQ:
            return None
        try:
            r = requests.post(
                "https://api.groq.com/openai/v1/chat/completions",
                headers={"Authorization": f"Bearer {config.Config.GROQ}"},
                json={
                    "model": "llama3-8b-8192",
                    "messages": [self._base_prompt(patient, diag)],
                    "temperature": 0.3
                },
                timeout=10
            ).json()
            return json.loads(r["choices"][0]["message"]["content"])
        except:
            return None

    # ---------- HuggingFace ----------
    def _hf(self, patient, diag):
        if not config.Config.HF:
            return None
        try:
            r = requests.post(
                "https://api-inference.huggingface.co/models/google/flan-t5-base",
                headers={"Authorization": f"Bearer {config.Config.HF}"},
                json={"inputs": self._base_prompt(patient, diag)["content"]},
                timeout=15
            ).json()
            return json.loads(r[0]["generated_text"])
        except:
            return None
