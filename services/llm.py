import requests, json, config

class LLM:
    def generate_report(self, patient, diag):
        for fn in (
            ("Gemini", self._gemini),
            ("ChatGPT", self._chatgpt),
            ("Groq", self._groq),
            ("HuggingFace", self._hf),
        ):
            name, func = fn
            print(f"[LLM] Trying {name}...")
            result = func(patient, diag)
            if result:
                print(f"[LLM]  Response generated by {name}")
                return result

        print("[LLM]  No LLM responded successfully")
        return None


    def _base_prompt(self, patient, diag):
        return {
            "role": "user",
            "content": f"""
    You are a healthcare AI assistant specializing in ophthalmology. Write this report as an ophthalmologist would for a patient.

    Return STRICT JSON only. No markdown. No explanations outside JSON.

    Guidelines:
    - Be concise and structured
    - Use bullet points for key information
    - Summarize when possible
    - Use clinical language but remain clear
    - Focus on actionable information

    Patient:
    Name: {patient.name}
    Age: {patient.age}
    Sex: {patient.sex}
    Weight: {patient.weight}
    Height: {patient.height}
    BMI: {patient.bmi}
    Insulin: {patient.insulin}
    Smoker: {patient.smoker}
    Alcohol: {patient.alcohol}
    Vascular Disease: {patient.vascular}

    Diagnosis:
    Left Eye: {diag['retinopathy_left']}
    Right Eye: {diag['retinopathy_right']}
    Confidence: {diag['confidence']}
    Risk Score: {diag['risk']}


JSON schema - Each field should contain structured, concise content:
{{
"condition_overview": "Brief 2-3 sentence overview",
"patient_assessment": "Provide as a list of clear bullet points, each on a new line starting with •",
"implications": "Provide as a list of clear bullet points, each on a new line starting with •",
"treatment_plan": "Structured as clear sections:\n• Lifestyle: [specific recommendations]\n• Monitoring: [specific plan]\n• Medical: [if any]\n• Follow-up: [schedule]",
"life_impact": "Brief impact summary",
"financial_impact": "Key cost points as bullet points",
"recovery_projection": "Realistic prognosis",
"additional_assessments": "Bulleted list of recommended tests",
"compliance_notice": "Standard disclaimer"
}}

IMPORTANT: For bullet points, use proper formatting with each bullet on its own line.
Example:
• First point
• Second point
• Third point
    """
        }

    # ---------- ChatGPT ----------
    def _chatgpt(self, patient, diag):
        if not config.Config.OPENAI:
            return None
        try:
            r = requests.post(
                "https://api.openai.com/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {config.Config.OPENAI}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": "gpt-4o-mini",
                    "messages": [self._base_prompt(patient, diag)],
                    "temperature": 0.3
                },
                timeout=10
            ).json()
            return json.loads(r["choices"][0]["message"]["content"])
        except:
            return None

    # ---------- Gemini ----------
    def _gemini(self, patient, diag):
        if not config.Config.GEMINI:
            return None
        try:
            from google import genai
            c = genai.Client(api_key=config.Config.GEMINI)
            r = c.models.generate_content(
                model="gemini-2.5-flash",
                contents=self._base_prompt(patient, diag)["content"]
            )
            return json.loads(r.text)
        except:
            return None

    # ---------- Groq ----------
    def _groq(self, patient, diag):
        if not config.Config.GROQ:
            return None
        try:
            r = requests.post(
                "https://api.groq.com/openai/v1/chat/completions",
                headers={"Authorization": f"Bearer {config.Config.GROQ}"},
                json={
                    "model": "llama3-8b-8192",
                    "messages": [self._base_prompt(patient, diag)],
                    "temperature": 0.3
                },
                timeout=10
            ).json()
            return json.loads(r["choices"][0]["message"]["content"])
        except:
            return None

    # ---------- HuggingFace ----------
    def _hf(self, patient, diag):
        if not config.Config.HF:
            return None
        try:
            r = requests.post(
                "https://api-inference.huggingface.co/models/google/flan-t5-base",
                headers={"Authorization": f"Bearer {config.Config.HF}"},
                json={"inputs": self._base_prompt(patient, diag)["content"]},
                timeout=15
            ).json()
            return json.loads(r[0]["generated_text"])
        except:
            return None
